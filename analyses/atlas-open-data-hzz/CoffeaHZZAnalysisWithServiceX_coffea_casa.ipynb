{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ecaa56-ddb5-445e-bbe6-4097165365aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: aiostream in /opt/conda/lib/python3.8/site-packages (0.4.3)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (7.6.5)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (1.0.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.27.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.3.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.4.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.2)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (58.0.4)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.0.9)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.1.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.1.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.11.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.11.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.2)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n",
      "env: USER=cms-jovyan\n"
     ]
    }
   ],
   "source": [
    "# Temporary hacks for coffea-casa: fixes will be available in new coffea-casa image\n",
    "!pip install aiostream ipywidgets\n",
    "%env USER cms-jovyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b3fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this notebook to work, you need to set up your environment as specified in the readme of https://github.com/gordonwatts/pyhep-2021-SX-OpenDataDemo\n",
    "\n",
    "import asyncio\n",
    "import numpy as np\n",
    "from coffea.processor.servicex import Analysis, DataSource, LocalExecutor\n",
    "from func_adl import ObjectStream\n",
    "from func_adl_servicex import ServiceXSourceUpROOT\n",
    "from servicex.servicex import ServiceXDataset\n",
    "import hist\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import infofile # Same infofile used in https://github.com/atlas-outreach-data-tools/notebooks-collection-opendata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24197a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'root://eospublic.cern.ch//eos/opendata/atlas/OutreachDatasets/2020-01-22/4lep/'\n",
    "\n",
    "fileset = {'Data': [prefix + 'Data/data_A.4lep.root',\n",
    "                    prefix + 'Data/data_B.4lep.root',\n",
    "                    prefix + 'Data/data_C.4lep.root',\n",
    "                    prefix + 'Data/data_D.4lep.root'],\n",
    "           'Background $Z,tt^{bar}$': [prefix + 'MC/mc_361106.Zee.4lep.root',\n",
    "                                       prefix + 'MC/mc_361107.Zmumu.4lep.root',\n",
    "                                       prefix + 'MC/mc_410000.ttbar_lep.4lep.root'],\n",
    "           'Background $ZZ^{star}$': [prefix + 'MC/mc_363490.llll.4lep.root'],\n",
    "           'Signal ($m_H$ = 125 GeV)': [prefix + 'MC/mc_345060.ggH125_ZZ4lep.4lep.root',\n",
    "                                        prefix + 'MC/mc_344235.VBFH125_ZZ4lep.4lep.root',\n",
    "                                        prefix + 'MC/mc_341964.WH125_ZZ4lep.4lep.root',\n",
    "                                        prefix + 'MC/mc_341947.ZH125_ZZ4lep.4lep.root']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be2a6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method from https://github.com/atlas-outreach-data-tools/notebooks-collection-opendata\n",
    "\n",
    "lumi = 10 # fb-1 # data_A,data_B,data_C,data_D\n",
    "\n",
    "def get_xsec_weight(sample):\n",
    "    info = infofile.infos[sample] # open infofile\n",
    "    xsec_weight = (lumi*1000*info[\"xsec\"])/(info[\"sumw\"]*info[\"red_eff\"]) #*1000 to go from fb-1 to pb-1\n",
    "    return xsec_weight # return cross-section weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3cd3ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from method from https://github.com/atlas-outreach-data-tools/notebooks-collection-opendata\n",
    "\n",
    "def calc_mllll(lep_pt,lep_eta,lep_phi,lep_E):\n",
    "    # first lepton is [0], 2nd lepton is [1] etc\n",
    "    px_0 = lep_pt[:,0]*np.cos(lep_phi[:,0]) # x-component of lep[0] momentum\n",
    "    py_0 = lep_pt[:,0]*np.sin(lep_phi[:,0]) # y-component of lep[0] momentum\n",
    "    pz_0 = lep_pt[:,0]*np.sinh(lep_eta[:,0]) # z-component of lep[0] momentum\n",
    "    px_1 = lep_pt[:,1]*np.cos(lep_phi[:,1]) # x-component of lep[1] momentum\n",
    "    py_1 = lep_pt[:,1]*np.sin(lep_phi[:,1]) # y-component of lep[1] momentum\n",
    "    pz_1 = lep_pt[:,1]*np.sinh(lep_eta[:,1]) # z-component of lep[1] momentum\n",
    "    px_2 = lep_pt[:,2]*np.cos(lep_phi[:,2]) # x-component of lep[2] momentum\n",
    "    py_2 = lep_pt[:,2]*np.sin(lep_phi[:,2]) # y-component of lep[2] momentum\n",
    "    pz_2 = lep_pt[:,2]*np.sinh(lep_eta[:,2]) # z-component of lep[3] momentum\n",
    "    px_3 = lep_pt[:,3]*np.cos(lep_phi[:,3]) # x-component of lep[3] momentum\n",
    "    py_3 = lep_pt[:,3]*np.sin(lep_phi[:,3]) # y-component of lep[3] momentum\n",
    "    pz_3 = lep_pt[:,3]*np.sinh(lep_eta[:,3]) # z-component of lep[3] momentum\n",
    "    sumpx = px_0 + px_1 + px_2 + px_3 # x-component of 4-lepton momentum\n",
    "    sumpy = py_0 + py_1 + py_2 + py_3 # y-component of 4-lepton momentum\n",
    "    sumpz = pz_0 + pz_1 + pz_2 + pz_3 # z-component of 4-lepton momentum\n",
    "    sumE = lep_E[:,0] + lep_E[:,1] + lep_E[:,2] + lep_E[:,3] # energy of 4-lepton system\n",
    "    return np.sqrt(sumE**2 - sumpx**2 - sumpy**2 - sumpz**2)/1000 #/1000 to go from MeV to GeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1515ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from methods from https://github.com/atlas-outreach-data-tools/notebooks-collection-opendata\n",
    "\n",
    "# cut on lepton charge\n",
    "# paper: \"selecting two pairs of isolated leptons, each of which is comprised of two leptons with the same flavour and opposite charge\"\n",
    "def cut_lep_charge(lep_charge):\n",
    "# throw away when sum of lepton charges is not equal to 0\n",
    "# first lepton is [0], 2nd lepton is [1] etc\n",
    "    return ((lep_charge[:,0] + lep_charge[:,1] + lep_charge[:,2] + lep_charge[:,3]) != 0)\n",
    "\n",
    "# cut on lepton type\n",
    "# paper: \"selecting two pairs of isolated leptons, each of which is comprised of two leptons with the same flavour and opposite charge\"\n",
    "def cut_lep_type(lep_type):\n",
    "# for an electron lep_type is 11\n",
    "# for a muon lep_type is 13\n",
    "# throw away when none of eeee, mumumumu, eemumu\n",
    "    sum_lep_type = lep_type[:,0] + lep_type[:,1] + lep_type[:,2] + lep_type[:,3]\n",
    "    return ((sum_lep_type != 44) & (sum_lep_type != 48) & (sum_lep_type != 52))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f451f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HZZAnalysis(Analysis):\n",
    "    def process(self, events):\n",
    "        # Get dataset name and lepton information from events\n",
    "        dataset = events.metadata['dataset']\n",
    "        leptons = events.lep\n",
    "        \n",
    "        # Cut events based on lepton charge, then update leptons\n",
    "        events = events[~cut_lep_charge(leptons.charge)]\n",
    "        leptons = events.lep\n",
    "        \n",
    "        # Cut events based on lepton type, then update leptons\n",
    "        events = events[~cut_lep_type(leptons.typeid)]\n",
    "        leptons = events.lep\n",
    "        \n",
    "        # Calculate the mllll for each event\n",
    "        mllll = calc_mllll(leptons.pt, leptons.eta, leptons.phi, leptons.energy)\n",
    "        \n",
    "        if (dataset == 'Data'):\n",
    "            # Create and fill a histogram for mllll\n",
    "            mllllhist = (\n",
    "                hist.Hist.new\n",
    "                .Reg(34, 80, 250, name='mllll', label='4-lepton invariant mass $\\mathrm{m_{4l}}$ [GeV]')\n",
    "                .StrCat(['Data'], name='dataset', label='Dataset')\n",
    "                .Weight()\n",
    "                .fill(mllll=mllll, dataset=dataset)\n",
    "            )\n",
    "        else:\n",
    "            # Extract the sample name from the filename metadata with regex\n",
    "            sample = re.findall(r'mc_\\d+\\.(.+)\\.4lep', events.metadata['filename'])[0]\n",
    "            \n",
    "            # Calculate the event weights\n",
    "            totalWeights = get_xsec_weight(sample) * events.mcWeight * events.scaleFactor\n",
    "            \n",
    "            # Create and fill a weighted histogram for mllll\n",
    "            mllllhist = (\n",
    "                hist.Hist.new\n",
    "                .Reg(34, 80, 250, name='mllll', label='4-lepton invariant mass $\\mathrm{m_{4l}}$ [GeV]')\n",
    "                .StrCat(['Background $Z,tt^{bar}$', 'Background $ZZ^{star}$', 'Signal ($m_H$ = 125 GeV)'], name='dataset', label='Dataset')\n",
    "                .Weight()\n",
    "                .fill(mllll=mllll, dataset=dataset, weight=totalWeights)\n",
    "            )\n",
    "        \n",
    "        return {\n",
    "            'entries': len(events),\n",
    "            'mllll': mllllhist\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31361726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from methods from https://github.com/gordonwatts/pyhep-2021-SX-OpenDataDemo\n",
    "\n",
    "def good_leptons(source: ObjectStream) -> ObjectStream:\n",
    "    '''Select out all good leptons from each event. Return their pt, eta, phi, and E, and other\n",
    "    things needed downstream.\n",
    "\n",
    "    Because uproot doesn't tie together the objects, we can't do any cuts at this point.\n",
    "    '''\n",
    "    return source.Select(lambda e:\n",
    "        {\n",
    "            'lep_pt': e.lep_pt,\n",
    "            'lep_eta': e.lep_eta,\n",
    "            'lep_phi': e.lep_phi,\n",
    "            'lep_energy': e.lep_E,\n",
    "            'lep_charge': e.lep_charge,\n",
    "            'lep_typeid': e.lep_type,\n",
    "            'mcWeight': e.mcWeight,\n",
    "            'scaleFactor': e.scaleFactor_ELE*e.scaleFactor_MUON*e.scaleFactor_LepTRIGGER*e.scaleFactor_PILEUP,\n",
    "        })\n",
    "\n",
    "def make_ds(name: str, query: ObjectStream):\n",
    "    '''Create a ServiceX Datasource for a particular ATLAS Open data file\n",
    "    '''\n",
    "    datasets = [ServiceXDataset(fileset[name], backend_name='open_uproot')]\n",
    "    return DataSource(query=query, metadata={'dataset': name}, datasets=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ec9ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from method from https://github.com/gordonwatts/pyhep-2021-SX-OpenDataDemo\n",
    "\n",
    "async def run_analysis():\n",
    "    '''Run on a known analysis file/files and return the result.\n",
    "    Should be fine to start many of these at once.\n",
    "    '''\n",
    "    # Parse the dataset\n",
    "    ds_names = list(fileset.keys())\n",
    "\n",
    "    # Create the query\n",
    "    ds = ServiceXSourceUpROOT('cernopendata://dummy',  'mini', backend_name='open_uproot')\n",
    "    ds.return_qastle = True\n",
    "    leptons = good_leptons(ds)\n",
    "\n",
    "    # Get data source for this run\n",
    "    executor = LocalExecutor()\n",
    "    datasources = [make_ds(ds_name, leptons) for ds_name in ds_names]\n",
    "\n",
    "    # Create the analysis and we can run from there\n",
    "    analysis = HZZAnalysis()\n",
    "\n",
    "    async def run_updates_stream(accumulator_stream, name):\n",
    "        '''Run to get the last item in the stream'''\n",
    "        coffea_info = None\n",
    "        try:\n",
    "            async for coffea_info in accumulator_stream:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Failure while processing {name}') from e\n",
    "        return coffea_info\n",
    "\n",
    "    all_plots = await asyncio.gather(*[run_updates_stream(executor.execute(analysis, source), source.metadata['dataset']) for source in datasources])\n",
    "\n",
    "    # Combine the MC plots\n",
    "    all_MC_plots = [p['mllll'] for p in all_plots[1:]]\n",
    "    MC_plot = all_MC_plots[0]\n",
    "    for p in all_MC_plots[1:]:\n",
    "        MC_plot += p\n",
    "\n",
    "    return {\n",
    "        'Data': all_plots[0]['mllll'],\n",
    "        'MC': MC_plot\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "180cbad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[root://eospublic.ce...:   0%|          | 0/9000000000.0 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30b8cf766a44131a5db7546d484c18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "        [root://eospublic.ce... Downloaded:   0%|          | 0/9000000000.0 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Exception",
     "evalue": "Failure while processing Data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4968/2106446225.py\u001b[0m in \u001b[0;36mrun_updates_stream\u001b[0;34m(accumulator_stream, name)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcoffea_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccumulator_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/servicex/executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, analysis, datasource, title)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mfinished_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstreamer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0masync_accumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreamer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/accumulator.py\u001b[0m in \u001b[0;36masync_accumulate\u001b[0;34m(result_stream)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/aiostream/stream/advanced.py\u001b[0m in \u001b[0;36mbase_combine\u001b[0;34m(source, switch, ordered, task_limit)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/aiostream/stream/create.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miscoroutinefunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/servicex/executor.py\u001b[0m in \u001b[0;36minline_wait\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;34m\"This could be inline, but python 3.6\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/servicex/local_executor.py\u001b[0m in \u001b[0;36m_async_analysis\u001b[0;34m(self, events_url, tree_name, data_type, meta_data, process_func)\u001b[0m\n\u001b[1;32m     58\u001b[0m     ):\n\u001b[0;32m---> 59\u001b[0;31m         return run_coffea_processor(\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mevents_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevents_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/servicex/executor.py\u001b[0m in \u001b[0;36mrun_coffea_processor\u001b[0;34m(events_url, tree_name, proc, data_type, meta_data)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4968/3092488649.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, events)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# Extract the sample name from the filename metadata with regex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'mc_\\d+\\.(.+)\\.4lep'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4968/1842051641.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mrun_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfinish_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4968/2106446225.py\u001b[0m in \u001b[0;36mrun_analysis\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcoffea_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mall_plots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun_updates_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasources\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Combine the MC plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4968/2106446225.py\u001b[0m in \u001b[0;36mrun_updates_stream\u001b[0;34m(accumulator_stream, name)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Failure while processing {name}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcoffea_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Failure while processing Data"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "output = await run_analysis()\n",
    "finish_time = time.time()\n",
    "\n",
    "print(\"Total runtime in seconds: \" + str(finish_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca8527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histograms\n",
    "hist.Hist.plot1d(output['Data'], histtype='errorbar', color='black')\n",
    "hist.Hist.plot1d(output['MC'], stack=True, histtype='fill', color=['purple', 'red', 'cyan'])\n",
    "\n",
    "# Basic bin parameters\n",
    "xmin = 80\n",
    "xmax = 250\n",
    "step_size = 5\n",
    "\n",
    "bin_centers = np.arange(start=xmin+step_size/2, # The interval includes this value\n",
    "                        stop=xmax+step_size/2, # The interval doesn't include this value\n",
    "                        step=step_size ) # Spacing between values\n",
    "\n",
    "# Calculate background statistical uncertainty\n",
    "# Remove the \"[:,:2]\" expressions to use all MC datasets with background and signal combined\n",
    "mc_tot_var = np.sum(output['MC'].variances()[:,:2], axis=1)\n",
    "mc_err = np.sqrt(mc_tot_var)\n",
    "mc_tot_height = np.sum(output['MC'].values()[:,:2], axis=1)\n",
    "\n",
    "# Plot background statistical uncertainty\n",
    "plt.bar(bin_centers, # x\n",
    "        2*mc_err, # heights\n",
    "        alpha=0.5, # half transparency\n",
    "        bottom=mc_tot_height-mc_err, color='none', \n",
    "        hatch=\"////\", width=step_size, label='Stat. Unc.')\n",
    "\n",
    "# Tune plot appearance\n",
    "main_axes = plt.gca()\n",
    "main_axes.set_xlim(left=xmin, right=xmax)\n",
    "main_axes.set_ylim(bottom=0, top=np.amax(output['Data'].values())*1.6)\n",
    "main_axes.set_ylabel('Events / '+str(step_size)+' GeV')\n",
    "main_axes.legend(frameon=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

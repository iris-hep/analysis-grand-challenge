{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b547996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FILES_MAX_PER_SAMPLE = -1  # input files per process, set to -1 for no limit / 1 or 10 for quick debugging  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda82b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "from coffea import processor\n",
    "import hist\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Processor(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        num_bins = 10\n",
    "        bin_low = 0\n",
    "        bin_high = 500\n",
    "        name = \"mass\"\n",
    "        label = \"m [GeV]\"\n",
    "        self.hist = (\n",
    "            hist.Hist.new.Reg(num_bins, bin_low, bin_high, name=name, label=label)\n",
    "            .StrCat([], name=\"category\", label=\"Category\", growth=True)\n",
    "            .StrCat([], name=\"variation\", label=\"Systematic variation\", growth=True)\n",
    "            .Weight()\n",
    "        )\n",
    "\n",
    "    def process(self, events):\n",
    "        histogram = self.hist.copy()\n",
    "\n",
    "        category = events.metadata[\"dataset\"]  # \"ttbar\" etc.\n",
    "        variation = events.metadata[\"variation\"]  # \"nominal\" etc.\n",
    "\n",
    "        # normalization for MC\n",
    "        x_sec = events.metadata[\"xsec\"]\n",
    "        nevts_total = events.metadata[\"nevts\"]\n",
    "        lumi = 3378 # /pb\n",
    "        if category != \"data\":\n",
    "            xsec_weight = x_sec * lumi / nevts_total\n",
    "        else:\n",
    "            xsec_weight = 1\n",
    "\n",
    "        selected_jets = events.jet[events.jet.pt > 25]  # pT > 25 GeV for jets\n",
    "        cut_btag = (\n",
    "            ak.sum(selected_jets.btag > 0.2, axis=1) > 2\n",
    "        )  # more than two btags (\"tag\" means > 0.2 score)\n",
    "\n",
    "        selected_events = events[cut_btag]\n",
    "\n",
    "        histogram.fill(\n",
    "            mass=ak.sum(selected_events.jet, axis=-1).mass, category=category, variation=variation, weight=xsec_weight\n",
    "        )\n",
    "\n",
    "        output = {\"nevents\": {category: len(events)}, \"hist\": histogram}\n",
    "\n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9417d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.nanoevents.schemas.base import BaseSchema, zip_forms\n",
    "from coffea.nanoevents.methods import base, vector\n",
    "from coffea.nanoevents import transforms\n",
    "\n",
    "\n",
    "# https://github.com/mat-adamec/agc_coffea/blob/main/agc_schema.py\n",
    "class AGCSchema(BaseSchema):\n",
    "    def __init__(self, base_form):\n",
    "        super().__init__(base_form)\n",
    "        self._form[\"contents\"] = self._build_collections(self._form[\"contents\"])\n",
    "\n",
    "    def _build_collections(self, branch_forms):\n",
    "        names = set([k.split('_')[0] for k in branch_forms.keys() if not (k.startswith('number'))])\n",
    "        # Remove n(names) from consideration. It's safe to just remove names that start with n, as nothing else begins with n in our fields.\n",
    "        # Also remove GenPart, PV and MET because they deviate from the pattern of having a 'number' field.\n",
    "        names = [k for k in names if not (k.startswith('n') | k.startswith('met') | k.startswith('GenPart') | k.startswith('PV'))]\n",
    "        output = {}\n",
    "        for name in names:\n",
    "            offsets = transforms.counts2offsets_form(branch_forms['number' + name])\n",
    "            content = {k[len(name)+1:]: branch_forms[k] for k in branch_forms if (k.startswith(name + \"_\") & (k[len(name)+1:] != 'e'))}\n",
    "            # Add energy separately so its treated correctly by the p4 vector.\n",
    "            content['energy'] = branch_forms[name+'_e']\n",
    "            # Check for LorentzVector\n",
    "            output[name] = zip_forms(content, name, 'PtEtaPhiELorentzVector', offsets=offsets)\n",
    "\n",
    "        # Handle GenPart, PV, MET. Note that all the nPV_*'s should be the same. We just use one.\n",
    "        output['met'] = zip_forms({k[len('met')+1:]: branch_forms[k] for k in branch_forms if k.startswith('met_')}, 'met')\n",
    "        #output['GenPart'] = zip_forms({k[len('GenPart')+1:]: branch_forms[k] for k in branch_forms if k.startswith('GenPart_')}, 'GenPart', offsets=transforms.counts2offsets_form(branch_forms['numGenPart']))\n",
    "        output['PV'] = zip_forms({k[len('PV')+1:]: branch_forms[k] for k in branch_forms if (k.startswith('PV_') & ('npvs' not in k))}, 'PV', offsets=transforms.counts2offsets_form(branch_forms['nPV_x']))\n",
    "        return output\n",
    "\n",
    "    @property\n",
    "    def behavior(self):\n",
    "        behavior = {}\n",
    "        behavior.update(base.behavior)\n",
    "        behavior.update(vector.behavior)\n",
    "        return behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b1f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using https://atlas-groupdata.web.cern.ch/atlas-groupdata/dev/AnalysisTop/TopDataPreparation/XSection-MC15-13TeV.data\n",
    "# x-secs are in pb\n",
    "xsec_info = {\n",
    "    \"ttbar\": 396.87 + 332.97, # nonallhad + allhad, keep same x-sec for all\n",
    "    \"single_top_s_chan\": 2.0268 + 1.2676,\n",
    "    \"single_top_t_chan\": 36.993 + 22.175,\n",
    "    \"single_top_tW\": 37.936 + 37.906,\n",
    "    \"wjets\": 61457 * 0.252,  # e/mu+nu final states\n",
    "    \"data\": None\n",
    "}\n",
    "\n",
    "# list of files\n",
    "with open(\"ntuples.json\") as f:\n",
    "    file_info = json.load(f)\n",
    "\n",
    "# process into \"fileset\" summarizing all info\n",
    "fileset = {}\n",
    "variation = \"nominal\"\n",
    "for process in file_info.keys():\n",
    "    file_list = file_info[process][variation][\"files\"]\n",
    "    file_paths = [f[\"path\"] for f in file_list[:N_FILES_MAX_PER_SAMPLE]]\n",
    "    nevts_total = sum([f[\"nevts\"] for f in file_list[:N_FILES_MAX_PER_SAMPLE]])\n",
    "    metadata = {\"variation\": variation, \"nevts\": nevts_total, \"xsec\": xsec_info[process]}\n",
    "    fileset.update({process: {\"files\": file_paths, \"metadata\": metadata}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fce979",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_DASK = True\n",
    "\n",
    "if USE_DASK:\n",
    "    from dask.distributed import Client\n",
    "\n",
    "    client = Client(\"tls://localhost:8786\")\n",
    "    executor = processor.DaskExecutor(client=client)\n",
    "else:\n",
    "    executor = processor.IterativeExecutor()\n",
    "\n",
    "run = processor.Runner(executor=executor, schema=AGCSchema, savemetrics=True)\n",
    "\n",
    "output, metrics = run(fileset, \"events\", processor_instance=Processor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b41cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"hist\"][:, \"ttbar\", \"nominal\"].plot(stack=True, label=\"ttbar\")\n",
    "output[\"hist\"][:, \"wjets\", \"nominal\"].plot(stack=True, label=\"wjets\")\n",
    "output[\"hist\"][:, \"single_top_s_chan\", \"nominal\"].plot(stack=True, label=\"s-chan\")\n",
    "output[\"hist\"][:, \"single_top_t_chan\", \"nominal\"].plot(stack=True, label=\"t-chan\")\n",
    "output[\"hist\"][:, \"single_top_tW\", \"nominal\"].plot(stack=True, label=\"tW\")\n",
    "\n",
    "output[\"hist\"][:, \"data\", \"nominal\"].plot(label=\"data\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.gcf()\n",
    "fig.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
